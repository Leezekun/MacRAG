api:
  zp_key: ""
  openai_key: ""
  openai_base_url: ""
  lanchain_api_key: ""

model_path:
  emb_model: "intfloat/multilingual-e5-large"
  rerank_model: "cross-encoder/ms-marco-MiniLM-L-12-v2"
  chatglm3-6b-8k: "THUDM/chatglm3-6b"
  chatglm3-6b-32k: "THUDM/chatglm3-6b-32k"
  longalign-7b-64k: "THUDM/LongAlign-7B-64k"
  vicuna-v1.5-7b-16k: "lmsys/vicuna-7b-v1.5"
  llama2-13b-chat-longlora: "Yukang/Llama-2-13b-chat-longlora-32k-sft"
  llama3-70b-8k: "meta-llama/Llama-3-70B-Instruct"
  longrag-chatglm3-32k: ""
  longrag-qwen1.5-32k: ""
  longrag-vicuna-v1.5-16k: ""
  longrag-llama3-8k: ""
  longrag-llama2-4k: ""
  qwen1.5-7b-chat-32k: "Qwen/Qwen1.5-7B-Chat"
  qwen2.5-7b-instruct: "Qwen/Qwen2.5-7B-Instruct"
  qwen2.5-14b-instruct: "Qwen/Qwen2.5-14B-Instruct"
  llama3-8b-instruct-8k: "meta-llama/Meta-Llama-3-8B-Instruct"
  llama3.1-8b-instruct: "meta-llama/Llama-3.1-8B-Instruct"
  mistral-7b-instruct-v0.1: "mistralai/Mistral-7B-Instruct-v0.1"
  mistral-7b-instruct-v0.3: "mistralai/Mistral-7B-Instruct-v0.3"
  gemma-2-9b-it: "google/gemma-2-9b-it"

model_maxlen:
  gpt-4o: 30000
  gpt-4o-mini: 15000
  gpt-4o: 15000
  gpt-3.5-turbo-16k: 15000
  gpt-3.5-turbo-0125: 15000
  glm-4: 7000
  chatglm3-6b-8k: 7000
  chatglm3-6b-32k: 30000
  longalign-7b-64k: 60000
  vicuna-v1.5-7b-16k: 15000
  llama2-13b-chat-longlora: 30000
  qwen1.5-7b-chat-32k: 30000
  qwen2.5-7b-instruct: 20000
  qwen2.5-14b-instruct: 30000
  llama3-8b-instruct-8k: 7000
  llama3.1-8b-instruct: 30000
  mistral-7b-instruct-v0.1: 30000
  mistral-7b-instruct-v0.3: 30000
  gemma-2-9b-it: 7000
  longrag-chatglm3-32k: 30000
  longrag-qwen1.5-32k: 30000
  longrag-vicuna-v1.5-16k: 15000
  longrag-llama3-8k: 7000
  longrag-llama2-32k: 30000
  llama3-70b-8k: 7000
  longrag-llama2-4k: 3500
  longrag-llama2-13b-4k: 3500
  gemini-1.5-pro: 100000
  gemini-1.5-flash: 100000
